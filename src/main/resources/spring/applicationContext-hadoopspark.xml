<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:aop="http://www.springframework.org/schema/aop"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:tx="http://www.springframework.org/schema/tx"
	xsi:schemaLocation="
	http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd
	http://www.springframework.org/schema/beans
	http://www.springframework.org/schema/beans/spring-beans.xsd      
	http://www.springframework.org/schema/tx
    http://www.springframework.org/schema/tx/spring-tx-3.0.xsd
	http://www.springframework.org/schema/aop
	http://www.springframework.org/schema/aop/spring-aop-3.0.xsd">
	<!-- author minn -->
 <description>hadoop spark  config</description>
 
  <context:property-placeholder ignore-unresolvable="true" location="classpath*:/spring/application.hadoopspark.properties" />
  <bean id="hdfsFileUtils" class="p.minn.hadoop.hdfs.HDFSFileUtils">
        <constructor-arg value="hdfs://${minn.hdfs.defaultFS}"/>
		<property name="input" value="${minn.hdfs.input}"/>
	    <property name="output" value="${minn.hdfs.output}"/>
	    <property name="driverClass" value="${jdbc.hdfs.driver}"/> 
		<property name="dbUrl" value="${jdbc.hdfs.url}"/> 
		<property name="username" value="${jdbc.hdfs.username}"/> 
		<property name="password" value="${jdbc.hdfs.password}"/>    
  </bean>
    <bean id="hdfsdataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"> 
		<property name="driverClassName" value="${jdbc.hdfs.driver}"/> 
		<property name="url" value="${jdbc.hdfs.url}"/> 
		<property name="username" value="${jdbc.hdfs.username}"/> 
		<property name="password" value="${jdbc.hdfs.password}"/> 
	</bean> 

	<bean id="hdfstransactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
		<property name="dataSource" ref="hdfsdataSource" />
	</bean>
	 
    <tx:annotation-driven transaction-manager="hdfstransactionManager"/>
   <!-- define the SqlSessionFactory -->
	<bean id="hdfsSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean" >
		<property name="dataSource" ref="hdfsdataSource" />
		<property name="typeAliasesPackage" value="p.minn.hadoop.entity" />
		<property name="mapperLocations" value="classpath:/mybatis/hadoop/*Mapper.xml" />
	</bean>

   <bean id="hdfsSession" class="org.mybatis.spring.SqlSessionTemplate" >
       <constructor-arg index="0" ref="hdfsSessionFactory"></constructor-arg>
   </bean>
   
	<!-- scan for mappers and let them be autowired -->
	<bean id="hdfsmapperScannerConfigurer" class="org.mybatis.spring.mapper.MapperScannerConfigurer">
		<property name="basePackage" value="p.minn.hadoop.repository" />
		<property name="sqlSessionFactoryBeanName" value="hdfsSessionFactory"/>
	</bean>
	
	 <bean id="sparkConf" class="org.apache.spark.SparkConf" >
       <property name="appName" value="${minn.spark.appName}" />
		<property name="master" value="${minn.spark.master}"/>
   </bean>
   
   <bean id="javaSparkContext" class="org.apache.spark.api.java.JavaSparkContext" >
       <constructor-arg index="0" ref="sparkConf"></constructor-arg>
   </bean>
	
	<bean id="sqlContext" class="org.apache.spark.sql.SQLContext" >
       <constructor-arg index="0" ref="javaSparkContext"></constructor-arg>
   </bean>
	
	<bean id="hadoopSparkJDBC" class="p.minn.spark.jdbc.HadoopSparkJDBC">
	  <constructor-arg index="0" value="${jdbc.hdfs.url}"></constructor-arg>
	  <constructor-arg index="1" value="${jdbc.hdfs.driver}"></constructor-arg>
	  <constructor-arg index="2" value="${jdbc.hdfs.username}"></constructor-arg>
	  <constructor-arg index="3" value="${jdbc.hdfs.password}"></constructor-arg>
	   <property name="javaSparkContext" ref="javaSparkContext" />
	   <property name="sqlContext" ref="sqlContext" />
	</bean>
</beans>